## Introduction
The Metropolis-Hastings (MH) algorithm is a cornerstone of computational statistics, particularly in the field of Bayesian inference and Markov Chain Monte Carlo (MCMC) methods. It provides a powerful technique for generating samples from complex probability distributions where direct sampling is challenging. 
## Markov Chains and Invariant Distributions

### Markov Chains in Continuous State Spaces
A Markov chain is a stochastic process where the probability of transitioning to the next state depends only on the current state, not on the sequence of events that preceded it. In mathematical terms, for a sequence of random variables $\{\theta^{(i)}\}$, the Markov property is expressed as:
$$
P(\theta^{(i)} \mid \theta^{(i-1)}, \theta^{(i-2)}, \dots, \theta^{(1)}) = T(\theta^{(i)} \mid \theta^{(i-1)})
$$
Here, $T(\theta^{(i)} \mid \theta^{(i-1)})$ is the transition kernel, representing the probability density of moving from state $\theta^{(i-1)}$ to state $\theta^{(i)}$.

### Transition Kernels and Invariant Measures
The transition kernel $P(x,dy)$ describes the probabilities of moving from a point $x$ to a measurable set $dy$ in the state space $\mathbb{R}^d$:

For a continuous state space, $P(x,dy)$ is a probability measure satisfying:
$$
\int_{\mathbb{R}^d} P(x,dy) = 1
$$

An invariant measure $\pi(\cdot)$ of the Markov chain satisfies:
$$
\int_{\mathbb{R}^d} P(x,dy) \pi(x) dx = \pi(dy)
$$

This means that if the chain starts with the distribution $\pi$, it will remain in $\pi$ after each transition.

### Objective
Our goal is to construct a Markov chain with a transition kernel $P(x,dy)$ such that $\pi(\cdot)$ is its invariant distribution. Specifically, we aim to sample from $\pi(y) dy$, where $\pi(y)$ is a target probability density function.

## Constructing the Transition Kernel

### Defining the Transition Kernel
Consider a function $p(x, y)$ that represents the probability density of transitioning from state $x$ to state $y$. We define the transition kernel $P(x, dy)$ as:
$$
P(x, dy) = p(x, y) dy + r(x) \delta_x(dy)
$$
Here:
- $p(x, y)$ is the proposal density for moving from $x$ to $y$, where $x \neq y$.
- $\delta_x(dy)$ is the Dirac delta measure centered at $x$, representing the probability of remaining in the same state.
- $r(x)$ is the probability of staying at state $x$, ensuring that the total probability sums to 1.

### Normalization Condition
For $P(x, dy)$ to be a valid transition kernel, it must satisfy:

$$
\int_{\mathbb{R}^d} P(x, dy) = 1
$$

Given that $p(x, x) = 0$ (since we assume no direct probability of proposing to stay at the same state), we have:
$$
\int_{\mathbb{R}^d} P(x, dy) = \int_{\mathbb{R}^d} p(x, y) dy + r(x) = 1
$$

Therefore, the probability of remaining at $x$ is:
$$
r(x) = 1 - \int_{\mathbb{R}^d} p(x, y) dy
$$

## Reversibility and Invariant Distributions
A sufficient condition for $\pi(\cdot)$ to be an invariant distribution of the Markov chain is reversibility, also known as the detailed balance condition. Reversibility requires that:
$$
\pi(x) p(x, y) = \pi(y) p(y, x)
$$

This condition ensures that the flow of probability from $x$ to $y$ is balanced by the flow from $y$ to $x$ in the stationary distribution.

## The Metropolis-Hastings Algorithm

### Proposal Distribution
We start by introducing a proposal distribution $q(x, y)$, which is a probability density function satisfying:
$$
\int_{\mathbb{R}^d} q(x, y) dy = 1
$$

The proposal distribution suggests a candidate state $y$ given the current state $x$. However, the proposal distribution alone may not ensure that $\pi(\cdot)$ is the invariant distribution, especially if $q(x, y)$ is not symmetric or does not satisfy the reversibility condition with respect to $\pi(\cdot)$.

### Acceptance Probability
To correct for the discrepancy and enforce reversibility, we introduce an acceptance probability $\alpha(x, y)$, which adjusts the probability of moving from $x$ to $y$. The acceptance probability must satisfy $0 \leq \alpha(x, y) \leq 1$.

We aim to define $\alpha(x, y)$ such that the modified transition probability $p(x, y) = q(x, y) \alpha(x, y)$ satisfies the reversibility condition:
$$
\pi(x) p(x, y) = \pi(y) p(y, x)
$$

### Deriving the Acceptance Probability
To find $\alpha(x, y)$, we consider two cases:

1. **Case 1**: $\pi(x) q(x, y) \geq \pi(y) q(y, x)$
   
   In this case, the proposed move from $x$ to $y$ is less favorable. To satisfy the reversibility condition, we set:$$
   \alpha(x, y) = \frac{\pi(y) q(y, x)}{\pi(x) q(x, y)}
   $$

2. **Case 2**: $\pi(x) q(x, y) < \pi(y) q(y, x)$
   
   In this case, the proposed move is more favorable, so we set:$$
   \alpha(x, y) = 1
   $$

### Combining Both Cases
To encapsulate both cases, we define the acceptance probability as:

$$
\alpha(x, y) = \min \left(1, \frac{\pi(y) q(y, x)}{\pi(x) q(x, y)} \right)
$$

This formula ensures that $\alpha(x, y) \leq 1$ and that the reversibility condition is satisfied in all cases.

### The Metropolis-Hastings Transition Kernel
With the acceptance probability defined, the transition kernel $P_{MH}(x, dy)$ for the Metropolis-Hastings algorithm becomes:
$$
P_{MH}(x, dy) = q(x, y) \alpha(x, y) dy + \left[1 - \int_{\mathbb{R}^d} q(x, y) \alpha(x, y) dy\right] \delta_x(dy)
$$

## Algorithm Summary
The Metropolis-Hastings algorithm proceeds as follows:

1. **Initialize**: Start from an initial state $x^{(0)}$.

2. **Iteration ($i \geq 1$)**:
   - **Proposal Step**: Sample a candidate state $y$ from the proposal distribution $q(x^{(i-1)}, y)$.
   - **Acceptance Probability**: Compute the acceptance probability: $$
     \alpha(x^{(i-1)}, y) = \min \left(1, \frac{\pi(y) q(y, x^{(i-1)})}{\pi(x^{(i-1)}) q(x^{(i-1)}, y)} \right)
     $$
   - **Acceptance Step**: Generate a uniform random number $u \sim \text{Uniform}(0, 1)$. If $u \leq \alpha(x^{(i-1)}, y)$, accept $y$ as the next state $x^{(i)} = y$. Otherwise, set $x^{(i)} = x^{(i-1)}$.

3. **Repeat**: Continue the iteration for the desired number of steps.

## Handling Unnormalized Densities
In many practical applications, the target density $\pi(x)$ may be known only up to a normalizing constant, $\pi(x) = \frac{\phi(x)}{Z}$. The acceptance probability simplifies to:
$$
\alpha(x, y) = \min \left(1, \frac{\phi(y) q(y, x)}{\phi(x) q(x, y)} \right)
$$

## Conclusion
The Metropolis-Hastings algorithm is a fundamental tool for sampling from complex probability distributions. By carefully constructing a transition kernel that satisfies the reversibility condition, we ensure that the Markov chain has the desired invariant distribution.

To deepen your understanding and explore advanced topics, consider the following resources:

### Books
- *Monte Carlo Statistical Methods* by Christian P. Robert and George Casella.
- *Markov Chain Monte Carlo in Practice* by W.R. Gilks, S. Richardson, and D.J. Spiegelhalter.

### Topics
- **Convergence Diagnostics**: Techniques to assess when a Markov chain has reached its stationary distribution.
- **High-Dimensional Sampling**: Challenges and solutions in applying MCMC methods to high-dimensional spaces.
- **Variational Inference**: An alternative to MCMC for approximate inference in complex models.
